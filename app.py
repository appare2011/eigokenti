import streamlit as st
import streamlit.components.v1 as components

st.set_page_config(page_title="Pro English Trainer", layout="centered")

st.title("ğŸ›¡ï¸ ç©¶æ¥µï¼šéŸ³éŸ¿ãƒ»æ–‡å­—ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç›£è¦–")
st.markdown("æ–‡å­—ã«ãªã‚‹å‰ã®**ã€éŸ³ã®éŸ¿ãã€**ã«é•å’Œæ„ŸãŒã‚ã‚Œã°å³åœæ­¢ã—ã¾ã™ã€‚")

st_js = f"""
<div id="status" style="padding:10px; border-radius:5px; background:#111; color:#0f0; margin-bottom:10px; font-family:monospace; border:1px solid #333;">
    SYSTEM_READY...
</div>

<canvas id="visualizer" style="width:100%; height:100px; background:#000; border-radius:10px; margin-bottom:10px;"></canvas>

<div id="warning-screen" style="display:none; position:fixed; top:0; left:0; width:100%; height:100%; background:#7b0000; color:white; z-index:9999; justify-content:center; align-items:center; flex-direction:column; text-align:center;">
    <h1 style="font-size:60px; margin:0; font-family:sans-serif;">ğŸš¨ STOP! ğŸš¨</h1>
    <p id="detected-text" style="font-size:24px; margin:20px; font-family:monospace; background:rgba(0,0,0,0.3); padding:10px;"></p>
    <button onclick="location.reload()" style="padding:20px 40px; font-size:24px; border:none; border-radius:10px; cursor:pointer; background:white; color:#7b0000; font-weight:bold;">REBOOT SYSTEM</button>
</div>

<button id="start-btn" style="padding:25px; width:100%; background:#0044cc; color:white; border:none; border-radius:15px; font-size:22px; cursor:pointer; font-weight:bold; box-shadow: 0 5px #002266;">
    START MISSION
</button>

<div id="log-container" style="margin-top:20px; width:100%; height:250px; border:2px solid #333; border-radius:10px; padding:15px; overflow-y:scroll; background:#000; color:#0f0; font-family:'Courier New', monospace; font-size:20px;">
</div>

<script>
    let recognition;
    let audioContext;
    let analyser;
    let dataArray;
    let animationId;

    const canvas = document.getElementById('visualizer');
    const ctx = canvas.getContext('2d');

    // --- 1. éŸ³éŸ¿ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼ï¼ˆéŸ³ã®å‹•ãã‚’è¦–è¦šåŒ–ï¼‰ ---
    function visualize(stream) {{
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const source = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;
        const bufferLength = analyser.frequencyBinCount;
        dataArray = new Uint8Array(bufferLength);

        function draw() {{
            animationId = requestAnimationFrame(draw);
            analyser.getByteFrequencyData(dataArray);
            ctx.fillStyle = 'rgb(0, 0, 0)';
            ctx.fillRect(0, 0, canvas.width, canvas.height);

            let barWidth = (canvas.width / bufferLength) * 2.5;
            let barHeight;
            let x = 0;

            for(let i = 0; i < bufferLength; i++) {{
                barHeight = dataArray[i] / 2;
                ctx.fillStyle = 'rgb(0,' + (barHeight + 100) + ',0)';
                ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
                x += barWidth + 1;
            }}
        }}
        draw();
    }}

    // --- 2. æ–‡å­—ç›£è¦–ï¼ˆè¶…é€Ÿãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰ ---
    function initRecognition() {{
        const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
        recognition = new SpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';

        recognition.onresult = (event) => {{
            for (let i = event.resultIndex; i < event.results.length; ++i) {{
                const transcript = event.results[i][0].transcript.toLowerCase();
                
                // ã€20ç‚¹ã‚’100ç‚¹ã«ã™ã‚‹åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã€‘
                // iPadãŒå‹æ‰‹ã«ã€ŒçŠ¬ã€ã‚„ã€ŒCanyouã€ã«å¤‰æ›ã™ã‚‹éç¨‹ã®ã€ŒéŸ³ã®æºã‚‰ãã€ã‚’æ­£è¦è¡¨ç¾ã§æ•æ‰
                const isJapanese = /[^ -~]/.test(transcript); // ã‹ãªãƒ»æ¼¢å­—
                const isRomaji = /nni|tti|ssi|rru|hha|nno|ssu|kku|[aiueo]{{3,}}/.test(transcript); // ãƒ­ãƒ¼ãƒå­—
                const isSuspicious = (transcript.length > 10 && !transcript.includes(' ')); // ç•°å¸¸ã«é•·ã„å˜èª

                if (isJapanese || isRomaji || isSuspicious) {{
                    triggerWarning(transcript);
                    return;
                }}

                if (event.results[i].isFinal) {{
                    document.getElementById('log-container').innerHTML += '<div>> ' + transcript.toUpperCase() + '</div>';
                }}
            }}
        }};

        recognition.onstart = () => {{
            document.getElementById('status').innerText = "SYSTEM_ACTIVE: MONITORING_SOUND_WAVES";
            document.getElementById('status').style.color = "#0f0";
        }};
    }}

    function triggerWarning(text) {{
        cancelAnimationFrame(animationId);
        document.getElementById('warning-screen').style.display = 'flex';
        document.getElementById('detected-text').innerText = "DETECTION: " + text;
        recognition.stop();
        if(audioContext) audioContext.close();
    }}

    document.getElementById('start-btn').onclick = async () => {{
        const stream = await navigator.mediaDevices.getUserMedia({{ audio: true }});
        visualize(stream);
        initRecognition();
        recognition.start();
        document.getElementById('start-btn').style.display = 'none';
    }};
</script>
"""

components.html(st_js, height=750)
